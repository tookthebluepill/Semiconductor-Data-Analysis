{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRfu54PXoCNnLpXgubIAZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tookthebluepill/Semiconductor-Data-Analysis/blob/main/secomdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "KKB0Wtq9M_Z5",
        "outputId": "b96c61ec-f8df-4449-bcbc-ce03d3756055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "secom.data íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a4bffbb1-1e07-4c95-bb0c-b7b4a1655d80\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a4bffbb1-1e07-4c95-bb0c-b7b4a1655d80\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secom.data to secom.data\n",
            "Saving secom_labels.data to secom_labels.data\n",
            "User uploaded file \"secom.data\" with length 5389983 bytes\n",
            "User uploaded file \"secom_labels.data\" with length 40638 bytes\n",
            "\n",
            "secom_labels.data íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-47a6ced6-7f45-4623-ae64-4df036249f24\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-47a6ced6-7f45-4623-ae64-4df036249f24\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3832858824.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nsecom_labels.data íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"secom.data íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')\n",
        "\n",
        "print(\"\\nsecom_labels.data íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1ë‹¨ê³„ì—ì„œ ì—…ë¡œë“œí•œ íŒŒì¼ë“¤ì„ pandas ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "# feature ë°ì´í„°\n",
        "features = pd.read_csv('secom.data', delim_whitespace=True, header=None)\n",
        "features.columns = [f'feature_{i+1}' for i in range(features.shape[1])]\n",
        "\n",
        "# label ë°ì´í„°\n",
        "labels = pd.read_csv('secom_labels.data', delim_whitespace=True, header=None)\n",
        "labels.columns = ['label', 'timestamp']\n",
        "\n",
        "# ë‘ ë°ì´í„°í”„ë ˆì„ì„ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
        "secom_df = pd.concat([features, labels], axis=1)\n",
        "\n",
        "# í•©ì³ì§„ ë°ì´í„°ì˜ ìƒìœ„ 5ê°œ í–‰ê³¼ ê¸°ë³¸ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "print(\"### ë³‘í•©ëœ SECOM ë°ì´í„°ì…‹ (ìƒìœ„ 5ê°œ í–‰) ###\")\n",
        "print(secom_df.head())\n",
        "\n",
        "print(\"\\n### ë°ì´í„°í”„ë ˆì„ ì •ë³´ ###\")\n",
        "secom_df.info()\n",
        "\n",
        "# Colab í™˜ê²½ì— í•©ì³ì§„ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•´ë‘ë©´ í¸ë¦¬í•©ë‹ˆë‹¤.\n",
        "secom_df.to_csv('secom_combined.csv', index=False)\n",
        "print(\"\\n'secom_combined.csv' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢Œì¸¡ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ í™•ì¸í•´ë³´ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbwydpWcNkWL",
        "outputId": "898d37d2-4d0d-45f5-8683-3ddc4ca207d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-561960878.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  features = pd.read_csv('secom.data', delim_whitespace=True, header=None)\n",
            "/tmp/ipython-input-2-561960878.py:10: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  labels = pd.read_csv('secom_labels.data', delim_whitespace=True, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ë³‘í•©ëœ SECOM ë°ì´í„°ì…‹ (ìƒìœ„ 5ê°œ í–‰) ###\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
            "0    3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
            "1    3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
            "2    2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
            "3    2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
            "4    3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
            "\n",
            "   feature_7  feature_8  feature_9  feature_10  ...  feature_583  feature_584  \\\n",
            "0    97.6133     0.1242     1.5005      0.0162  ...       0.5005       0.0118   \n",
            "1   102.3433     0.1247     1.4966     -0.0005  ...       0.5019       0.0223   \n",
            "2    95.4878     0.1241     1.4436      0.0041  ...       0.4958       0.0157   \n",
            "3   104.2367     0.1217     1.4882     -0.0124  ...       0.4990       0.0103   \n",
            "4   100.3967     0.1235     1.5031     -0.0031  ...       0.4800       0.4766   \n",
            "\n",
            "   feature_585  feature_586  feature_587  feature_588  feature_589  \\\n",
            "0       0.0035       2.3630          NaN          NaN          NaN   \n",
            "1       0.0055       4.4447       0.0096       0.0201       0.0060   \n",
            "2       0.0039       3.1745       0.0584       0.0484       0.0148   \n",
            "3       0.0025       2.0544       0.0202       0.0149       0.0044   \n",
            "4       0.1045      99.3032       0.0202       0.0149       0.0044   \n",
            "\n",
            "   feature_590  label            timestamp  \n",
            "0          NaN     -1  19/07/2008 11:55:00  \n",
            "1     208.2045     -1  19/07/2008 12:32:00  \n",
            "2      82.8602      1  19/07/2008 13:17:00  \n",
            "3      73.8432     -1  19/07/2008 14:43:00  \n",
            "4      73.8432     -1  19/07/2008 15:22:00  \n",
            "\n",
            "[5 rows x 592 columns]\n",
            "\n",
            "### ë°ì´í„°í”„ë ˆì„ ì •ë³´ ###\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1567 entries, 0 to 1566\n",
            "Columns: 592 entries, feature_1 to timestamp\n",
            "dtypes: float64(590), int64(1), object(1)\n",
            "memory usage: 7.1+ MB\n",
            "\n",
            "'secom_combined.csv' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢Œì¸¡ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ í™•ì¸í•´ë³´ì„¸ìš”.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸\n",
        "# -1 (í•©ê²©), 1 (ë¶ˆëŸ‰) ë¼ë²¨ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë´…ë‹ˆë‹¤.\n",
        "print(\"### ë¼ë²¨ë³„ ë°ì´í„° ê°œìˆ˜ (í´ë˜ìŠ¤ ë¶ˆê· í˜•) ###\")\n",
        "print(secom_df['label'].value_counts())\n",
        "print(\"\\n=> í•©ê²©(1463ê°œ)ì— ë¹„í•´ ë¶ˆëŸ‰(104ê°œ) ë°ì´í„°ê°€ ë§¤ìš° ì ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\")\n",
        "\n",
        "\n",
        "# 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
        "# ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ë¹„ì–´ìˆëŠ” ê°’(NaN)ì„ ì±„ì›Œì¤˜ì•¼ í•©ë‹ˆë‹¤.\n",
        "# ê° ì—´ì˜ ì¤‘ì•™ê°’(median)ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš°ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.\n",
        "print(\"### ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘ ###\")\n",
        "# ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸° ì „, ëª‡ ê°œë‚˜ ìˆëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.\n",
        "print(f\"ì²˜ë¦¬ ì „ feature_1ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜: {secom_df['feature_1'].isnull().sum()}\")\n",
        "\n",
        "# ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
        "# timestamp ì—´ì€ ìˆ«ìê°€ ì•„ë‹ˆë¯€ë¡œ ì œì™¸í•˜ê³  ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "df_imputed = secom_df.fillna(secom_df.median(numeric_only=True))\n",
        "\n",
        "print(f\"ì²˜ë¦¬ í›„ feature_1ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜: {df_imputed['feature_1'].isnull().sum()}\")\n",
        "print(\"ëª¨ë“  ìˆ«ì ì—´ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. âœ…\")\n",
        "\n",
        "\n",
        "# ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸\n",
        "print(\"\\n### ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„ ë°ì´í„° (ìƒìœ„ 5ê°œ í–‰) ###\")\n",
        "print(df_imputed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA3AZu_MPFrK",
        "outputId": "29dd09a3-a733-4939-b098-e6501ae3aa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ë¼ë²¨ë³„ ë°ì´í„° ê°œìˆ˜ (í´ë˜ìŠ¤ ë¶ˆê· í˜•) ###\n",
            "label\n",
            "-1    1463\n",
            " 1     104\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=> í•©ê²©(1463ê°œ)ì— ë¹„í•´ ë¶ˆëŸ‰(104ê°œ) ë°ì´í„°ê°€ ë§¤ìš° ì ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "### ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘ ###\n",
            "ì²˜ë¦¬ ì „ feature_1ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜: 6\n",
            "ì²˜ë¦¬ í›„ feature_1ì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜: 0\n",
            "ëª¨ë“  ìˆ«ì ì—´ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. âœ…\n",
            "\n",
            "### ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„ ë°ì´í„° (ìƒìœ„ 5ê°œ í–‰) ###\n",
            "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
            "0    3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
            "1    3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
            "2    2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
            "3    2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
            "4    3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
            "\n",
            "   feature_7  feature_8  feature_9  feature_10  ...  feature_583  feature_584  \\\n",
            "0    97.6133     0.1242     1.5005      0.0162  ...       0.5005       0.0118   \n",
            "1   102.3433     0.1247     1.4966     -0.0005  ...       0.5019       0.0223   \n",
            "2    95.4878     0.1241     1.4436      0.0041  ...       0.4958       0.0157   \n",
            "3   104.2367     0.1217     1.4882     -0.0124  ...       0.4990       0.0103   \n",
            "4   100.3967     0.1235     1.5031     -0.0031  ...       0.4800       0.4766   \n",
            "\n",
            "   feature_585  feature_586  feature_587  feature_588  feature_589  \\\n",
            "0       0.0035       2.3630       0.0205       0.0148       0.0046   \n",
            "1       0.0055       4.4447       0.0096       0.0201       0.0060   \n",
            "2       0.0039       3.1745       0.0584       0.0484       0.0148   \n",
            "3       0.0025       2.0544       0.0202       0.0149       0.0044   \n",
            "4       0.1045      99.3032       0.0202       0.0149       0.0044   \n",
            "\n",
            "   feature_590  label            timestamp  \n",
            "0      71.9005     -1  19/07/2008 11:55:00  \n",
            "1     208.2045     -1  19/07/2008 12:32:00  \n",
            "2      82.8602      1  19/07/2008 13:17:00  \n",
            "3      73.8432     -1  19/07/2008 14:43:00  \n",
            "4      73.8432     -1  19/07/2008 15:22:00  \n",
            "\n",
            "[5 rows x 592 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# ì´ì „ì— ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš´ df_imputed ë°ì´í„°í”„ë ˆì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "# 'df_imputed'ê°€ ì—†ë‹¤ë©´ ì´ì „ ë‹¨ê³„ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n",
        "if 'df_imputed' not in locals():\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ 'df_imputed' ë°ì´í„°í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # ê°„ë‹¨í•œ ë³µêµ¬ ì½”ë“œ\n",
        "    secom_df = pd.read_csv('secom_combined.csv')\n",
        "    df_imputed = secom_df.fillna(secom_df.median(numeric_only=True))\n",
        "    print(\"'secom_combined.csv'ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê³  ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# 1. íŠ¹ì§•(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬\n",
        "# ëª¨ë¸ì— ì…ë ¥í•  featureì™€ ì˜ˆì¸¡í•  ëŒ€ìƒì¸ labelì„ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
        "# timestampëŠ” ëª¨ë¸ë§ì— ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œì™¸í•©ë‹ˆë‹¤.\n",
        "X = df_imputed.drop(['label', 'timestamp'], axis=1)\n",
        "y = df_imputed['label']\n",
        "\n",
        "\n",
        "# 2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
        "# ë°ì´í„°ë¥¼ 80%ëŠ” í•™ìŠµìš©ìœ¼ë¡œ, 20%ëŠ” í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# 3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE)\n",
        "# í•™ìŠµìš© ë°ì´í„°ì—ì„œë§Œ SMOTEë¥¼ ì ìš©í•˜ì—¬ ë¶ˆëŸ‰(1) ë°ì´í„°ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì›ë³¸ì˜ ë¶„í¬ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "print(f\"SMOTE ì ìš© ì „ í•™ìŠµ ë°ì´í„° ë¼ë²¨ ë¶„í¬:\\n{y_train.value_counts()}\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "print(f\"\\nSMOTE ì ìš© í›„ í•™ìŠµ ë°ì´í„° ë¼ë²¨ ë¶„í¬:\\n{y_train_resampled.value_counts()}\\n\")\n",
        "\n",
        "\n",
        "# 4. ëª¨ë¸ í•™ìŠµ\n",
        "# ë¶ˆê· í˜•ì´ ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
        "print(\"### ëª¨ë¸ í•™ìŠµ ì‹œì‘ ###\")\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. âœ…\")\n",
        "\n",
        "\n",
        "# 5. ëª¨ë¸ í‰ê°€\n",
        "# í•™ìŠµë˜ì§€ ì•Šì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "print(\"\\n### ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\")\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions, target_names=['í•©ê²© (-1)', 'ë¶ˆëŸ‰ (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc2ANzvXPUAZ",
        "outputId": "9ef7456c-c54c-440e-e307-06955e7428d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE ì ìš© ì „ í•™ìŠµ ë°ì´í„° ë¼ë²¨ ë¶„í¬:\n",
            "label\n",
            "-1    1170\n",
            " 1      83\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE ì ìš© í›„ í•™ìŠµ ë°ì´í„° ë¼ë²¨ ë¶„í¬:\n",
            "label\n",
            "-1    1170\n",
            " 1    1170\n",
            "Name: count, dtype: int64\n",
            "\n",
            "### ëª¨ë¸ í•™ìŠµ ì‹œì‘ ###\n",
            "ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. âœ…\n",
            "\n",
            "### ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     í•©ê²© (-1)       0.93      0.99      0.96       293\n",
            "      ë¶ˆëŸ‰ (1)       0.00      0.00      0.00        21\n",
            "\n",
            "    accuracy                           0.93       314\n",
            "   macro avg       0.47      0.50      0.48       314\n",
            "weighted avg       0.87      0.93      0.90       314\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì´ì „ ëª¨ë¸ì—ì„œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# ì¤‘ìš”ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ì–´ ì •ë ¬\n",
        "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# ê°€ì¥ ì¤‘ìš”í•œ 40ê°œ íŠ¹ì„±ì˜ ì´ë¦„ì„ ì„ íƒ\n",
        "top_n = 40\n",
        "important_features = feature_importance_df.head(top_n)['feature'].tolist()\n",
        "\n",
        "print(f\"### ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„± {top_n}ê°œ ###\")\n",
        "print(important_features)\n",
        "\n",
        "\n",
        "# 2. ì¤‘ìš” íŠ¹ì„±ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "print(\"\\n### ì¤‘ìš” íŠ¹ì„±ìœ¼ë¡œ ëª¨ë¸ ì¬í•™ìŠµ ë° í‰ê°€ ###\")\n",
        "\n",
        "# ì¤‘ìš” íŠ¹ì„±ë§Œìœ¼ë¡œ X ë°ì´í„°ë¥¼ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
        "X_important = X[important_features]\n",
        "y_important = y # yëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "\n",
        "# ë°ì´í„° ë¶„ë¦¬\n",
        "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_important, y_important, test_size=0.2, random_state=42, stratify=y_important)\n",
        "\n",
        "# SMOTE ì ìš©\n",
        "smote_imp = SMOTE(random_state=42)\n",
        "X_train_resampled_imp, y_train_resampled_imp = smote_imp.fit_resample(X_train_imp, y_train_imp)\n",
        "\n",
        "# ëª¨ë¸ ì¬í•™ìŠµ\n",
        "model_imp = RandomForestClassifier(random_state=42)\n",
        "model_imp.fit(X_train_resampled_imp, y_train_resampled_imp)\n",
        "\n",
        "# ëª¨ë¸ ì¬í‰ê°€\n",
        "predictions_imp = model_imp.predict(X_test_imp)\n",
        "print(\"\\n### ëª¨ë¸ ì¬í‰ê°€ ê²°ê³¼ ###\")\n",
        "print(classification_report(y_test_imp, predictions_imp, target_names=['í•©ê²© (-1)', 'ë¶ˆëŸ‰ (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mADHACwAXDMq",
        "outputId": "121968db-df29-47d6-ec8d-767983750d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„± 40ê°œ ###\n",
            "['feature_487', 'feature_346', 'feature_520', 'feature_512', 'feature_34', 'feature_96', 'feature_248', 'feature_214', 'feature_104', 'feature_32', 'feature_511', 'feature_434', 'feature_478', 'feature_386', 'feature_131', 'feature_60', 'feature_420', 'feature_206', 'feature_488', 'feature_101', 'feature_41', 'feature_127', 'feature_564', 'feature_352', 'feature_347', 'feature_125', 'feature_342', 'feature_337', 'feature_490', 'feature_176', 'feature_130', 'feature_112', 'feature_311', 'feature_122', 'feature_288', 'feature_184', 'feature_22', 'feature_110', 'feature_281', 'feature_59']\n",
            "\n",
            "### ì¤‘ìš” íŠ¹ì„±ìœ¼ë¡œ ëª¨ë¸ ì¬í•™ìŠµ ë° í‰ê°€ ###\n",
            "\n",
            "### ëª¨ë¸ ì¬í‰ê°€ ê²°ê³¼ ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     í•©ê²© (-1)       0.94      0.97      0.95       293\n",
            "      ë¶ˆëŸ‰ (1)       0.20      0.10      0.13        21\n",
            "\n",
            "    accuracy                           0.91       314\n",
            "   macro avg       0.57      0.53      0.54       314\n",
            "weighted avg       0.89      0.91      0.90       314\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoostì™€ LightGBM ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "!pip install xgboost lightgbm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# ì´ì „ì— ì •ì˜ëœ 'df_imputed', 'important_features' ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "if 'df_imputed' not in locals() or 'important_features' not in locals():\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ 'df_imputed' ë˜ëŠ” 'important_features'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # ê°„ë‹¨í•œ ë³µêµ¬ ì½”ë“œ\n",
        "    secom_df = pd.read_csv('secom_combined.csv')\n",
        "    df_imputed = secom_df.fillna(secom_df.median(numeric_only=True))\n",
        "    important_features = ['feature_487', 'feature_346', 'feature_520', 'feature_512', 'feature_34', 'feature_96', 'feature_248', 'feature_214', 'feature_104', 'feature_32', 'feature_511', 'feature_434', 'feature_478', 'feature_386', 'feature_131', 'feature_60', 'feature_420', 'feature_206', 'feature_488', 'feature_101', 'feature_41', 'feature_127', 'feature_564', 'feature_352', 'feature_347', 'feature_125', 'feature_342', 'feature_337', 'feature_490', 'feature_176', 'feature_130', 'feature_112', 'feature_311', 'feature_122', 'feature_288', 'feature_184', 'feature_22', 'feature_110', 'feature_281', 'feature_59']\n",
        "    print(\"'secom_combined.csv'ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# --- ë°ì´í„° ì¤€ë¹„ ê³¼ì • ---\n",
        "# 1. ì¤‘ìš” íŠ¹ì„±ìœ¼ë¡œ ë°ì´í„° ì„ íƒ\n",
        "X_important = df_imputed[important_features]\n",
        "y = df_imputed['label']\n",
        "\n",
        "# 2. ë¼ë²¨ ë³€ê²½ (-1 -> 0) âœ¨âœ¨ ì—¬ê¸°ë§Œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤! âœ¨âœ¨\n",
        "y_mapped = y.replace({-1: 0, 1: 1})\n",
        "\n",
        "# 3. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (y_mapped ì‚¬ìš©)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_important, y_mapped, test_size=0.2, random_state=42, stratify=y_mapped)\n",
        "\n",
        "# 4. SMOTEë¡œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- XGBoost ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ---\n",
        "print(\"=\"*20)\n",
        "print(\"ğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\")\n",
        "print(\"=\"*20)\n",
        "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"\\n### XGBoost ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\")\n",
        "print(classification_report(y_test, xgb_predictions, target_names=['í•©ê²© (0)', 'ë¶ˆëŸ‰ (1)']))\n",
        "\n",
        "\n",
        "# --- LightGBM ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ---\n",
        "print(\"\\n\" + \"=\"*20)\n",
        "print(\"ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\")\n",
        "print(\"=\"*20)\n",
        "lgbm_model = LGBMClassifier(random_state=42)\n",
        "lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
        "lgbm_predictions = lgbm_model.predict(X_test)\n",
        "\n",
        "print(\"\\n### LightGBM ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\")\n",
        "print(classification_report(y_test, lgbm_predictions, target_names=['í•©ê²© (0)', 'ë¶ˆëŸ‰ (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6UjSySkWoHk",
        "outputId": "f6294109-a90f-4fd9-d10b-7c8b0fb7a29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.16.0)\n",
            "====================\n",
            "ğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
            "====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [03:31:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### XGBoost ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      í•©ê²© (0)       0.94      0.99      0.96       293\n",
            "      ë¶ˆëŸ‰ (1)       0.20      0.05      0.08        21\n",
            "\n",
            "    accuracy                           0.92       314\n",
            "   macro avg       0.57      0.52      0.52       314\n",
            "weighted avg       0.89      0.92      0.90       314\n",
            "\n",
            "\n",
            "====================\n",
            "ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
            "====================\n",
            "[LightGBM] [Info] Number of positive: 1170, number of negative: 1170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10155\n",
            "[LightGBM] [Info] Number of data points in the train set: 2340, number of used features: 40\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "\n",
            "### LightGBM ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      í•©ê²© (0)       0.94      0.99      0.97       293\n",
            "      ë¶ˆëŸ‰ (1)       0.60      0.14      0.23        21\n",
            "\n",
            "    accuracy                           0.94       314\n",
            "   macro avg       0.77      0.57      0.60       314\n",
            "weighted avg       0.92      0.94      0.92       314\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- ë°ì´í„° ì¤€ë¹„ (ì´ì „ ë‹¨ê³„ë“¤ê³¼ ë™ì¼) ---\n",
        "# ì´ì „ì— ì •ì˜ëœ 'df_imputed', 'important_features' ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "if 'df_imputed' not in locals() or 'important_features' not in locals():\n",
        "    print(\"ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ 'df_imputed' ë˜ëŠ” 'important_features'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # ê°„ë‹¨í•œ ë³µêµ¬ ì½”ë“œ\n",
        "    secom_df = pd.read_csv('secom_combined.csv')\n",
        "    df_imputed = secom_df.fillna(secom_df.median(numeric_only=True))\n",
        "    important_features = ['feature_487', 'feature_346', 'feature_520', 'feature_512', 'feature_34', 'feature_96', 'feature_248', 'feature_214', 'feature_104', 'feature_32', 'feature_511', 'feature_434', 'feature_478', 'feature_386', 'feature_131', 'feature_60', 'feature_420', 'feature_206', 'feature_488', 'feature_101', 'feature_41', 'feature_127', 'feature_564', 'feature_352', 'feature_347', 'feature_125', 'feature_342', 'feature_337', 'feature_490', 'feature_176', 'feature_130', 'feature_112', 'feature_311', 'feature_122', 'feature_288', 'feature_184', 'feature_22', 'feature_110', 'feature_281', 'feature_59']\n",
        "    print(\"'secom_combined.csv'ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "X_important = df_imputed[important_features]\n",
        "y = df_imputed['label'].replace({-1: 0, 1: 1})\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_important, y, test_size=0.2, random_state=42, stratify=y)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# --- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ ---\n",
        "print(\"=\"*20)\n",
        "print(\"âš™ï¸ LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë©ë‹ˆë‹¤)\")\n",
        "print(\"=\"*20)\n",
        "\n",
        "# 1. íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì •ì˜\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [5, 10],\n",
        "    'num_leaves': [20, 31]\n",
        "}\n",
        "\n",
        "# 2. GridSearchCV ì„¤ì •\n",
        "# ì„±ëŠ¥ í‰ê°€ëŠ” 'f1' ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤. (ë¶ˆê· í˜• ë°ì´í„°ì— ì í•©)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=LGBMClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',\n",
        "    cv=3, # 3-fold cross-validation\n",
        "    verbose=1,\n",
        "    n_jobs=-1 # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
        ")\n",
        "\n",
        "# 3. íŠœë‹ ì‹¤í–‰\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# 4. ìµœì ì˜ íŒŒë¼ë¯¸í„°ì™€ ì ìˆ˜ ì¶œë ¥\n",
        "print(\"\\n### íŠœë‹ ê²°ê³¼ ###\")\n",
        "print(f\"ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {grid_search.best_params_}\")\n",
        "print(f\"ìµœê³  êµì°¨ ê²€ì¦ ì ìˆ˜ (F1-score): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "# --- ìµœì¢… í‰ê°€ ---\n",
        "print(\"\\n\" + \"=\"*20)\n",
        "print(\"ğŸ† íŠœë‹ëœ ìµœì¢… ëª¨ë¸ í‰ê°€\")\n",
        "print(\"=\"*20)\n",
        "\n",
        "# 5. ìµœì ì˜ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° í‰ê°€\n",
        "best_model = grid_search.best_estimator_\n",
        "final_predictions = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\n### ìµœì¢… ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\")\n",
        "print(classification_report(y_test, final_predictions, target_names=['í•©ê²© (0)', 'ë¶ˆëŸ‰ (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3jZnF63ZTs-",
        "outputId": "4e93586c-3b7f-4bd0-ccb6-ef499b431463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================\n",
            "âš™ï¸ LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë©ë‹ˆë‹¤)\n",
            "====================\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "[LightGBM] [Info] Number of positive: 1170, number of negative: 1170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10155\n",
            "[LightGBM] [Info] Number of data points in the train set: 2340, number of used features: 40\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "### íŠœë‹ ê²°ê³¼ ###\n",
            "ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'num_leaves': 31}\n",
            "ìµœê³  êµì°¨ ê²€ì¦ ì ìˆ˜ (F1-score): 0.9735\n",
            "\n",
            "====================\n",
            "ğŸ† íŠœë‹ëœ ìµœì¢… ëª¨ë¸ í‰ê°€\n",
            "====================\n",
            "\n",
            "### ìµœì¢… ëª¨ë¸ í‰ê°€ ê²°ê³¼ ###\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      í•©ê²© (0)       0.94      0.99      0.96       293\n",
            "      ë¶ˆëŸ‰ (1)       0.25      0.05      0.08        21\n",
            "\n",
            "    accuracy                           0.93       314\n",
            "   macro avg       0.59      0.52      0.52       314\n",
            "weighted avg       0.89      0.93      0.90       314\n",
            "\n"
          ]
        }
      ]
    }
  ]
}